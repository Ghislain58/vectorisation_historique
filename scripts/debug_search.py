from pathlib import Path
import sys
import json

import numpy as np
import faiss

# Ajouter src/ au PYTHONPATH
ROOT = Path(__file__).resolve().parents[1]
SRC = ROOT / "src"
sys.path.append(str(SRC))

from medieval_rag.embeddings.model_loader import load_embedding_model
from medieval_rag.embeddings.embedder import Embedder


def load_corpus(jsonl_path: Path):
    """
    Charge corpus_chunks.jsonl en mÃ©moire.
    Retourne :
      - records_by_id: dict chunk_id -> record
    """
    records_by_id = {}

    if not jsonl_path.exists():
        raise FileNotFoundError(f"Fichier JSONL introuvable : {jsonl_path}")

    print(f"ğŸ“‚ Chargement du corpus : {jsonl_path}")
    with jsonl_path.open("r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            rec = json.loads(line)
            cid = rec.get("chunk_id")
            if not cid:
                continue
            records_by_id[cid] = rec

    print(f"   â†’ {len(records_by_id)} chunks chargÃ©s")
    return records_by_id


def load_faiss_index(index_path: Path, ids_path: Path):
    """
    Charge l'index FAISS et la liste des chunk_ids correspondants.
    """
    if not index_path.exists():
        raise FileNotFoundError(f"Index FAISS introuvable : {index_path}")
    if not ids_path.exists():
        raise FileNotFoundError(f"Fichier d'IDs introuvable : {ids_path}")

    print(f"ğŸ“¦ Chargement index FAISS : {index_path}")
    index = faiss.read_index(str(index_path))

    print(f"ğŸ“„ Chargement IDs : {ids_path}")
    with ids_path.open("r", encoding="utf-8") as f:
        ids_list = json.load(f)

    print(f"   â†’ {len(ids_list)} IDs chargÃ©s, {index.ntotal} vecteurs dans l'index.")
    if len(ids_list) != index.ntotal:
        print("âš ï¸  Mismatch entre nombre d'IDs et nombre de vecteurs FAISS !")

    return index, ids_list


def pretty_print_result(rank, score, rec):
    """
    Affiche un chunk de maniÃ¨re lisible, avec entitÃ©s si prÃ©sentes.
    """
    doc_id = rec.get("doc_id")
    source = rec.get("source")
    title = rec.get("title")
    page_start = rec.get("page_start")
    page_end = rec.get("page_end")
    entities = rec.get("entities") or {}
    year_min = rec.get("year_min")
    year_max = rec.get("year_max")

    text_preview = (rec.get("text") or "").replace("\n", " ")
    if len(text_preview) > 300:
        text_preview = text_preview[:300] + "..."

    print(f"\n=== RÃ©sultat #{rank} â€” score={score:.4f} ===")
    print(f"ğŸ“š Doc   : {doc_id} ({source})")
    if title:
        print(f"ğŸ“ Titre : {title}")
    print(f"ğŸ“„ Pages : {page_start}â€“{page_end}")

    # EntitÃ©s
    persons = entities.get("persons") or []
    places = entities.get("places") or []
    years = entities.get("years") or []

    if persons or places or years or (year_min is not None or year_max is not None):
        print("ğŸ” EntitÃ©s dÃ©tectÃ©es :")
        if persons:
            print(f"   ğŸ‘¤ Persons : {', '.join(persons)}")
        if places:
            print(f"   ğŸ“ Places  : {', '.join(places)}")
        if years:
            print(f"   ğŸ“… Years   : {', '.join(map(str, years))}")
        if year_min is not None or year_max is not None:
            print(f"   â³ Interval : {year_min}â€“{year_max}")

    print(f"ğŸ“‘ Texte : {text_preview}")


def main():
    data_root = Path("data")
    jsonl_path = data_root / "chunks" / "standard" / "corpus_chunks.jsonl"
    index_dir = data_root / "embeddings" / "e5_large"
    index_path = index_dir / "index.faiss"
    ids_path = index_dir / "index_ids.json"

    # Chargement corpus + index
    records_by_id = load_corpus(jsonl_path)
    index, ids_list = load_faiss_index(index_path, ids_path)

    # Chargement modÃ¨le d'embedding
    print("ğŸ§  Chargement du modÃ¨le d'embedding pour les requÃªtes...")
    model, device = load_embedding_model(
        "intfloat/multilingual-e5-large",
        device="auto"
    )
    embedder = Embedder(model, max_batch_size=16)

    print("\nâœ… PrÃªt pour la recherche sÃ©mantique.")
    print("   Tape une question en franÃ§ais (ou latin), ou 'q' pour quitter.")

    while True:
        try:
            query = input("\nâ“ Question > ").strip()
        except (EOFError, KeyboardInterrupt):
            print("\nğŸ‘‹ Fin de session.")
            break

        if not query:
            continue
        if query.lower() in {"q", "quit", "exit"}:
            print("ğŸ‘‹ Fin de session.")
            break

        # Embedding de la requÃªte
        q_emb = embedder.embed_texts([query])[0]
        q_vec = np.array([q_emb], dtype="float32")

        # Recherche FAISS
        k = 5
        distances, indices = index.search(q_vec, k)

        print(f"\nğŸ” Top {k} rÃ©sultats pour : {query!r}")
        print(f"   indices bruts  : {indices[0].tolist()}")
        print(f"   distances brutes : {distances[0].tolist()}")

        shown = 0

        for rank, (dist, idx) in enumerate(zip(distances[0], indices[0]), start=1):
            if idx < 0 or idx >= len(ids_list):
                print(f"   âš ï¸ Index FAISS {idx} hors plage (0..{len(ids_list)-1})")
                continue

            chunk_id = ids_list[idx]
            rec = records_by_id.get(chunk_id)
            if not rec:
                print(f"   âš ï¸ chunk_id {chunk_id} introuvable dans corpus.")
                continue

            score = 1.0 / (1.0 + float(dist))
            pretty_print_result(rank, score, rec)
            shown += 1

        if shown == 0:
            print("   âš ï¸ Aucun rÃ©sultat affichable (problÃ¨me de mapping index â†” corpus ?)")


if __name__ == "__main__":
    main()
