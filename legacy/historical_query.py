# historical_query.py
# Moteur de requÃªtes sur la base vectorielle historique

from __future__ import annotations

import argparse
import json
from pathlib import Path
from typing import Any, Dict, List, Optional

import numpy as np
import torch
from chromadb import PersistentClient
from sentence_transformers import SentenceTransformer


class HistoricalQueryEngine:
    """
    Moteur de requÃªtes :
    - encode la question avec intfloat/multilingual-e5-large
    - interroge la collection Chroma "documents_historiques_v2"
    - applique ensuite des filtres souples sur les mÃ©tadonnÃ©es :
        * --person â†’ entities_persons
        * --place  â†’ entities_places
        * --year   â†’ entities_years
    """

    def __init__(
        self,
        db_path: Path,
        collection_name: str = "documents_historiques_v2",
    ) -> None:
        # Device
        if torch.cuda.is_available():
            self.device = "cuda"
            print("âœ… GPU dÃ©tectÃ© :", torch.cuda.get_device_name(0))
            print(
                "ðŸ“¥ Chargement du modÃ¨le : intfloat/multilingual-e5-large"
            )
        else:
            self.device = "cpu"
            print("âš ï¸  GPU non dÃ©tectÃ©, utilisation du CPU.")
            print(
                "ðŸ“¥ Chargement du modÃ¨le : intfloat/multilingual-e5-large"
            )

        # ModÃ¨le d'embedding
        self.model = SentenceTransformer(
            "intfloat/multilingual-e5-large",
            device=self.device,
        )

        # Client Chroma
        self.client = PersistentClient(path=str(db_path))
        self.collection = self.client.get_or_create_collection(collection_name)

    # ============================
    #   OUTILS SUR LES MÃ‰TADONNÃ‰ES
    # ============================

    def _parse_meta_list(self, value: Any) -> List[str]:
        """
        Normalise une mÃ©tadonnÃ©e en liste de strings :
        - liste â†’ liste (avec str() sur les Ã©lÃ©ments)
        - string JSON de liste â†’ liste
        - autre â†’ [str(value)]
        - None â†’ []
        """
        if value is None:
            return []

        if isinstance(value, list):
            return [str(x) for x in value]

        if isinstance(value, str):
            # Tentative de dÃ©codage JSON
            try:
                data = json.loads(value)
                if isinstance(data, list):
                    return [str(x) for x in data]
                else:
                    return [value]
            except Exception:
                return [value]

        return [str(value)]

    def _matches_filters(
        self,
        md: Dict[str, Any],
        person: Optional[str] = None,
        place: Optional[str] = None,
        year: Optional[str] = None,
    ) -> bool:
        """
        Applique les filtres de maniÃ¨re souple sur les mÃ©tadonnÃ©es d'un chunk.
        - person : substring insensible Ã  la casse dans entities_persons
        - place  : substring insensible Ã  la casse dans entities_places
        - year   : substring dans entities_years
        Tous les filtres fournis sont en AND.
        """

        def match_one(key: str, needle: Optional[str]) -> bool:
            if not needle:
                return True  # pas de filtre sur ce champ
            values = self._parse_meta_list(md.get(key))
            if not values:
                return False
            n = str(needle).lower()
            for item in values:
                if isinstance(item, str) and n in item.lower():
                    return True
            return False

        ok_person = match_one("entities_persons", person)
        ok_place = match_one("entities_places", place)
        ok_year = match_one("entities_years", year)

        return ok_person and ok_place and ok_year

    # ============================
    #   REQUÃŠTE PRINCIPALE
    # ============================

    def ask(
        self,
        query: str,
        person: Optional[str] = None,
        place: Optional[str] = None,
        year: Optional[str] = None,
        top_k: int = 10,
    ) -> List[Dict[str, Any]]:
        """
        Interroge la base vectorielle :
        1) Chroma : recherche sÃ©mantique large (sans where sur les entitÃ©s)
        2) Filtrage Python sur les mÃ©tadonnÃ©es (person/place/year)
        3) Retourne les top_k meilleurs rÃ©sultats filtrÃ©s
        """
        # 1) Embedding de la requÃªte
        q_emb = self.model.encode(
            [query],
            convert_to_numpy=True,
        )[0]

        # 2) RequÃªte Chroma SANS filtre d'entitÃ©s
        raw = self.collection.query(
            query_embeddings=[q_emb.tolist()],
            n_results=max(top_k, 100),
            include=["documents", "metadatas", "distances"],
        )

        docs = raw.get("documents", [[]])[0]
        metas = raw.get("metadatas", [[]])[0]
        dists = raw.get("distances", [[]])[0]

        # SÃ©curitÃ© si Chroma renvoie moins d'entrÃ©es que prÃ©vu
        n = min(len(docs), len(metas), len(dists))
        docs = docs[:n]
        metas = metas[:n]
        dists = dists[:n]

        # 3) Filtrage Python sur entitÃ©s
        results: List[Dict[str, Any]] = []
        for doc, md, dist in zip(docs, metas, dists):
            if self._matches_filters(md, person=person, place=place, year=year):
                results.append(
                    {
                        "document": doc,
                        "metadata": md,
                        "distance": float(dist),
                    }
                )

        # Tri par distance (au cas oÃ¹)
        results.sort(key=lambda r: r["distance"])
        return results[:top_k]

    # ============================
    #   AFFICHAGE
    # ============================

    def _format_entity_list(self, values: Any) -> str:
        lst = self._parse_meta_list(values)
        if not lst:
            return "â€”"
        # on limite l'affichage pour Ã©viter le bruit monstrueux
        if len(lst) > 10:
            return ", ".join(lst[:10]) + " ..."
        return ", ".join(lst)

    def pretty_print_results(
        self,
        query: str,
        results: List[Dict[str, Any]],
        person: Optional[str],
        place: Optional[str],
        year: Optional[str],
    ) -> None:
        print()
        print(f"ðŸ”Ž RequÃªte : {query}")
        if person:
            print(f"ðŸ‘¤ Filtre personne : {person}")
        if place:
            print(f"ðŸ“ Filtre lieu     : {place}")
        if year:
            print(f"ðŸ—“  Filtre annÃ©e   : {year}")
        print()

        if not results:
            print("âŒ Aucun rÃ©sultat trouvÃ© (aprÃ¨s filtrage).")
            return

        for idx, res in enumerate(results, 1):
            md = res["metadata"]
            doc = res["document"]
            dist = res["distance"]

            filename = md.get("filename", "â€”")
            folder = md.get("folder", "â€”")
            chunk_id = md.get("chunk_id", "â€”")

            print(f"-------------------- [{idx}] --------------------")
            print(
                f"ðŸ“„ {filename}  (dossier: {folder}, chunk: {chunk_id}, distance: {dist:.4f})"
            )
            print(f"ðŸ“‚ Source : {md.get('source', 'â€”')}")
            print(f"ðŸ“ Extrait : {doc[:400].replace('\n', ' ')}[...]")
            print()

            persons = self._format_entity_list(md.get("entities_persons"))
            places = self._format_entity_list(md.get("entities_places"))
            years = self._format_entity_list(md.get("entities_years"))

            if persons != "â€”":
                print(f"ðŸ‘¥ Personnes: {persons}")
            if places != "â€”":
                print(f"ðŸ“ Lieux    : {places}")
            if years != "â€”":
                print(f"ðŸ—“  AnnÃ©es   : {years}")

            print()

        print("âœ… TerminÃ©.")


# ============================
#   CLI
# ============================

def build_arg_parser() -> argparse.ArgumentParser:
    parser = argparse.ArgumentParser(
        description="Moteur de requÃªtes sur la base vectorielle historique."
    )
    parser.add_argument(
        "query",
        type=str,
        help="Question ou requÃªte textuelle (ex: 'organisation du territoire autour de Brioude au XIe siÃ¨cle')",
    )
    parser.add_argument(
        "--person",
        type=str,
        default=None,
        help="Filtre personne (ex: 'GÃ©raud', 'Montmorin')",
    )
    parser.add_argument(
        "--place",
        type=str,
        default=None,
        help="Filtre lieu (ex: 'Brioude')",
    )
    parser.add_argument(
        "--year",
        type=str,
        default=None,
        help="Filtre annÃ©e (ex: '1050' ou 'XIe siÃ¨cle')",
    )
    parser.add_argument(
        "--top_k",
        type=int,
        default=10,
        help="Nombre maximal de rÃ©sultats Ã  afficher (dÃ©faut: 10)",
    )
    return parser


def main() -> None:
    parser = build_arg_parser()
    args = parser.parse_args()

    engine = HistoricalQueryEngine(
        db_path=Path("./vector_db_historique"),
        collection_name="documents_historiques_v2",
    )

    results = engine.ask(
        query=args.query,
        person=args.person,
        place=args.place,
        year=args.year,
        top_k=args.top_k,
    )

    engine.pretty_print_results(
        query=args.query,
        results=results,
        person=args.person,
        place=args.place,
        year=args.year,
    )


if __name__ == "__main__":
    main()
