#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
analyse_corpus.py
-----------------
Outil d'inspection du corpus index√© dans Chroma.

Il se connecte √† la collection "documents_historiques" cr√©√©e par
historical_vectorizer.py et affiche :

- le nombre total de chunks ;
- la r√©partition par type de document :
    - cartulaire (is_cartulary)
    - charte (is_charter)
    - acad√©mique (is_academic)
    - autres
- une approximation du "dossier logique" √† partir du chemin :
    mes_documents_historiques/articles, cartulaires, theses, etc.
- la liste des institutions d√©tect√©es pour les cartulaires ;
- la r√©partition par langue dominante (dominant_lang).
"""

from collections import Counter
from pathlib import PurePosixPath

from chromadb import PersistentClient


def fetch_all_metadatas(collection, batch_size: int = 1000):
    """
    R√©cup√®re toutes les m√©tadonn√©es de la collection par paquets.
    On ne charge PAS les documents ni les embeddings, uniquement metadatas.
    """
    all_metas = []
    offset = 0

    while True:
        res = collection.get(
            include=["metadatas"],
            limit=batch_size,
            offset=offset,
        )
        metas = res.get("metadatas", [])
        if not metas:
            break

        all_metas.extend(metas)
        offset += len(metas)

    return all_metas


def guess_folder_from_source(source: str) -> str:
    """
    Essaie de d√©duire le ‚Äúdossier logique‚Äù √† partir du chemin complet.

    Exemple :
        /home/.../mes_documents_historiques/cartulaires/MonPDF.pdf
        -> folder = "cartulaires"

    Si rien n'est trouv√©, renvoie "UNKNOWN".
    """
    try:
        p = PurePosixPath(source)
    except Exception:
        return "UNKNOWN"

    parts = list(p.parts)
    if "mes_documents_historiques" in parts:
        idx = parts.index("mes_documents_historiques")
        if idx + 1 < len(parts):
            return parts[idx + 1]
    return "UNKNOWN"


def main():
    print("üîó Connexion √† la base Chroma‚Ä¶")
    client = PersistentClient(path="./vector_db_historique")
    col = client.get_or_create_collection("documents_historiques")

    print("üì• R√©cup√©ration des m√©tadonn√©es (pagination)‚Ä¶")
    metadatas = fetch_all_metadatas(col, batch_size=2000)
    total = len(metadatas)
    print(f"‚úÖ {total} chunks trouv√©s dans la collection.\n")

    by_type = Counter()
    by_folder = Counter()
    by_institution = Counter()
    by_lang = Counter()

    for m in metadatas:
        # Type de document
        if m.get("is_cartulary"):
            by_type["cartulary"] += 1
        elif m.get("is_charter"):
            by_type["charter"] += 1
        elif m.get("is_academic"):
            by_type["academic"] += 1
        else:
            by_type["other"] += 1

        # Dossier logique (d√©duit de "source")
        source = m.get("source", "") or ""
        folder = guess_folder_from_source(source)
        by_folder[folder] += 1

        # Institutions (cartulaires)
        inst = m.get("institution")
        if inst:
            by_institution[inst] += 1

        # Langue dominante
        dom = m.get("dominant_lang")
        if dom:
            by_lang[dom] += 1

    # === Affichages ===
    print("üìä Chunks par type de document :")
    if not by_type:
        print("  (aucun type d√©tect√©)")
    else:
        for t, c in by_type.most_common():
            print(f"  - {t:10s} : {c}")
    print()

    print("üìÇ Chunks par dossier logique (mes_documents_historiques/‚Ä¶):")
    if not by_folder:
        print("  (aucun chemin exploitable)")
    else:
        for f, c in by_folder.most_common():
            print(f"  - {f:20s} : {c}")
    print()

    print("üèõÔ∏è Institutions d√©tect√©es (cartulaires) :")
    if not by_institution:
        print("  (aucune institution renseign√©e)")
    else:
        for inst, c in by_institution.most_common():
            print(f"  - {inst:25s} : {c}")
    print()

    print("üåê Langue dominante :")
    if not by_lang:
        print("  (aucune info de langue dominante)")
    else:
        for lang, c in by_lang.most_common():
            print(f"  - {lang:10s} : {c}")
    print()

    print("‚úÖ Analyse simple termin√©e.")


if __name__ == "__main__":
    main()
