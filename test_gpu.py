#!/usr/bin/env python3
"""Test complet de la configuration GPU dans WSL2"""
import torch, sys

print("\n" + "="*70)
print("üîç TEST DE CONFIGURATION GPU")
print("="*70 + "\n")

# Infos syst√®me
print(f"üêç Python: {sys.version.split()[0]}")
print(f"üî• PyTorch: {torch.__version__}")
print(f"   CUDA disponible: {torch.cuda.is_available()}")
print(f"   CUDA version: {torch.version.cuda if torch.cuda.is_available() else 'N/A'}")

if torch.cuda.is_available():
    for i in range(torch.cuda.device_count()):
        props = torch.cuda.get_device_properties(i)
        print(f"üéÆ GPU [{i}]: {props.name}")
        print(f"   VRAM: {props.total_memory / 1e9:.2f} GB")
        print(f"   Compute Capability: {props.major}.{props.minor}")

    # Test allocation m√©moire
    print("\nüß™ Test allocation tensor sur GPU...")
    try:
        x = torch.rand((1000, 1000), device='cuda')
        print(f"‚úÖ Tensor cr√©√© sur {x.device}")
        del x
        torch.cuda.empty_cache()
    except Exception as e:
        print(f"‚ùå Erreur allocation: {e}")
else:
    print("\n‚ö†Ô∏è  GPU non disponible.")
    print("   V√©rifie les drivers NVIDIA pour WSL et red√©marre avec:")
    print("   wsl --shutdown")

print("\n" + "="*70)
if torch.cuda.is_available():
    print("‚úÖ CONFIGURATION COMPL√àTE ET FONCTIONNELLE")
else:
    print("‚ö†Ô∏è  GPU non d√©tect√© ou non disponible")
print("="*70 + "\n")
